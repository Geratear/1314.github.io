<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>千～葉(GeraTear)</title>
  
  <subtitle>你所关注的就是你的世界</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2021-09-07T12:05:11.971Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>Gera Tear</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title></title>
    <link href="http://example.com/2021/09/07/%E7%88%AC%E8%99%AB/%E8%B1%86%E7%93%A3%E7%88%AC%E5%8F%96%E4%B9%8Bgevent%E5%8D%8F%E7%A8%8B/"/>
    <id>http://example.com/2021/09/07/%E7%88%AC%E8%99%AB/%E8%B1%86%E7%93%A3%E7%88%AC%E5%8F%96%E4%B9%8Bgevent%E5%8D%8F%E7%A8%8B/</id>
    <published>2021-09-07T12:00:37.973Z</published>
    <updated>2021-09-07T12:05:11.971Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># ���ڣ�2021��9��7��20:04:333</span></span><br><span class="line"><span class="comment"># ���ߣ�GeraTear</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># ������̵߳��̳߳�</span></span><br><span class="line"><span class="comment"># multiprocessing.dummy �Ƕ�����ṩ�Ķ��߳̿�</span></span><br><span class="line"><span class="comment">#from multiprocessing.dummy import Pool</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#import threading</span></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="comment"># Python��Э�̿�</span></span><br><span class="line"><span class="keyword">import</span> gevent</span><br><span class="line"><span class="keyword">from</span> gevent <span class="keyword">import</span> monkey</span><br><span class="line"><span class="comment"># ���Ӳ���</span></span><br><span class="line">monkey.patch_all()</span><br><span class="line"><span class="comment"># gevent �����ǿ�����ͬ�����߼�����д�첽�ĳ���</span></span><br><span class="line"><span class="comment"># monkey.patch_all() ��Python����ִ�е�ʱ�򣬻ᶯ̬�Ľ��ײ������⣨socket��select���������������첽�Ŀ⡣</span></span><br><span class="line"><span class="comment"># �ó�����ִ�����������ʱ�򣬰��첽�ķ�ʽȥִ�С�</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanSpider</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.data_queue = Queue.Queue()</span><br><span class="line">        self.base_url = <span class="string">&quot;http://movie.douban.com/top250?start=&quot;</span></span><br><span class="line">        self.headers = &#123;<span class="string">&quot;User-Agent&quot;</span> : <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko&quot;</span>&#125;</span><br><span class="line">        self.num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_page</span>(<span class="params">self, url</span>):</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;[INFO]: ����ץȡ %s &quot;</span> % url</span><br><span class="line">        html = requests.get(url, headers = self.headers).content</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> html</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_page</span>(<span class="params">self, url</span>):</span></span><br><span class="line">        html = self.load_page(url)</span><br><span class="line">        html_obj = etree.HTML(html)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ��ǰҳ������е�Ӱ�����б�</span></span><br><span class="line">        node_list = html_obj.xpath(<span class="string">&quot;//div[@class=&#x27;info&#x27;]&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># ����ÿ����㣬����ȡֵ</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> node_list:</span><br><span class="line">            <span class="comment"># ��Ӱ����</span></span><br><span class="line">            title = node.xpath(<span class="string">&quot;.//span[@class=&#x27;title&#x27;]/text()&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># ��Ӱ����</span></span><br><span class="line">            score = node.xpath(<span class="string">&quot;.//span[@class=&#x27;rating_num&#x27;]/text()&quot;</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            self.data_queue.put(score + <span class="string">&quot;\t&quot;</span> + title)</span><br><span class="line">            self.num += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">self</span>):</span></span><br><span class="line">        url_list = [self.base_url + <span class="built_in">str</span>(num) <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">225</span> + <span class="number">1</span>, <span class="number">25</span>)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ���߳�</span></span><br><span class="line">        <span class="comment">#for url in url_list:</span></span><br><span class="line">        <span class="comment">#    self.parse_page(url)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ���߳�1</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        thread_list = []</span></span><br><span class="line"><span class="string">        for url in url_list:</span></span><br><span class="line"><span class="string">            # ����һ���̣߳���ָ��ִ�е�����</span></span><br><span class="line"><span class="string">            thread = threading.Thread(target = self.parse_page, args = [url])</span></span><br><span class="line"><span class="string">            # �����߳�</span></span><br><span class="line"><span class="string">            thread.start()</span></span><br><span class="line"><span class="string">            thread_list.append(thread)</span></span><br><span class="line"><span class="string">            # thread.join()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        # �����߳��������ȴ����е����߳̽������ټ���ִ�С�</span></span><br><span class="line"><span class="string">        for thread in thread_list:</span></span><br><span class="line"><span class="string">            thread.join()</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># ���߳�2</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        # ����10���̵߳��̳߳�</span></span><br><span class="line"><span class="string">        pool = Pool(len(url_list))</span></span><br><span class="line"><span class="string">        # map()�߽׺�������������������������</span></span><br><span class="line"><span class="string">        pool.map(self.parse_page, url_list)</span></span><br><span class="line"><span class="string">        # �ر��̳߳�</span></span><br><span class="line"><span class="string">        pool.close()</span></span><br><span class="line"><span class="string">        # �������̣߳��ȴ����߳̽���</span></span><br><span class="line"><span class="string">        pool.join()</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Э��</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        job_list = []</span></span><br><span class="line"><span class="string">        for url in url_list:</span></span><br><span class="line"><span class="string">            # ����Э������ִ��</span></span><br><span class="line"><span class="string">            job = gevent.spawn(self.parse_page, url)</span></span><br><span class="line"><span class="string">            job_list.append(job)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        # �ȴ�����Э���������</span></span><br><span class="line"><span class="string">        gevent.joinall(job_list)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        job_list = [gevent.spawn(self.parse_page, url) <span class="keyword">for</span> url <span class="keyword">in</span> url_list]</span><br><span class="line">        gevent.joinall(job_list)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Pythonic</span></span><br><span class="line">        <span class="comment"># gevent.joinall([gevent.spawn(self.parse_page, url) for url in url_list])</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> self.data_queue.empty():</span><br><span class="line">            <span class="built_in">print</span> self.data_queue.get()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span> self.num</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    douban = DoubanSpider()</span><br><span class="line">    start = time.time()</span><br><span class="line">    douban.main()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;[INFO]: Useing time %f seconds.&quot;</span> % (time.time() - start)</span><br><span class="line">    <span class="comment"># 3.92</span></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>爬虫基础篇——之多线程multipprocessing.dummy</title>
    <link href="http://example.com/2021/09/07/%E7%88%AC%E8%99%AB/%E8%B1%86%E7%93%A3%E7%88%AC%E5%8F%96%E2%80%94%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8Bmultiprocessing.dummy/"/>
    <id>http://example.com/2021/09/07/%E7%88%AC%E8%99%AB/%E8%B1%86%E7%93%A3%E7%88%AC%E5%8F%96%E2%80%94%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8Bmultiprocessing.dummy/</id>
    <published>2021-09-07T11:54:11.680Z</published>
    <updated>2021-09-07T11:59:49.798Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入多线程的线程池</span></span><br><span class="line"><span class="comment"># multiprocessing.dummy 是多进程提供的多线程库</span></span><br><span class="line"><span class="keyword">from</span> multiprocessing.dummy <span class="keyword">import</span> Pool</span><br><span class="line"></span><br><span class="line"><span class="comment">#import threading</span></span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanSpider</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.data_queue = Queue.Queue()</span><br><span class="line">        self.base_url = <span class="string">&quot;http://movie.douban.com/top250?start=&quot;</span></span><br><span class="line">        self.headers = &#123;<span class="string">&quot;User-Agent&quot;</span> : <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko&quot;</span>&#125;</span><br><span class="line">        self.num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_page</span>(<span class="params">self, url</span>):</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;[INFO]: 正在抓取 %s &quot;</span> % url</span><br><span class="line">        html = requests.get(url, headers = self.headers).content</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> html</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_page</span>(<span class="params">self, url</span>):</span></span><br><span class="line">        html = self.load_page(url)</span><br><span class="line">        html_obj = etree.HTML(html)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 当前页面的所有电影结点的列表</span></span><br><span class="line">        node_list = html_obj.xpath(<span class="string">&quot;//div[@class=&#x27;info&#x27;]&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 迭代每个结点，进行取值</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> node_list:</span><br><span class="line">            <span class="comment"># 电影标题</span></span><br><span class="line">            title = node.xpath(<span class="string">&quot;.//span[@class=&#x27;title&#x27;]/text()&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># 电影评分</span></span><br><span class="line">            score = node.xpath(<span class="string">&quot;.//span[@class=&#x27;rating_num&#x27;]/text()&quot;</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            self.data_queue.put(score + <span class="string">&quot;\t&quot;</span> + title)</span><br><span class="line">            self.num += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">self</span>):</span></span><br><span class="line">        url_list = [self.base_url + <span class="built_in">str</span>(num) <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">225</span> + <span class="number">1</span>, <span class="number">25</span>)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">#for url in url_list:</span></span><br><span class="line">        <span class="comment">#    self.parse_page(url)</span></span><br><span class="line"></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        thread_list = []</span></span><br><span class="line"><span class="string">        for url in url_list:</span></span><br><span class="line"><span class="string">            # 创建一个线程，并指定执行的任务</span></span><br><span class="line"><span class="string">            thread = threading.Thread(target = self.parse_page, args = [url])</span></span><br><span class="line"><span class="string">            # 启动线程</span></span><br><span class="line"><span class="string">            thread.start()</span></span><br><span class="line"><span class="string">            thread_list.append(thread)</span></span><br><span class="line"><span class="string">            # thread.join()</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        # 让主线程阻塞，等待所有的子线程结束，再继续执行。</span></span><br><span class="line"><span class="string">        for thread in thread_list:</span></span><br><span class="line"><span class="string">            thread.join()</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 创建10个线程的线程池</span></span><br><span class="line">        pool = Pool(<span class="built_in">len</span>(url_list))</span><br><span class="line">        <span class="comment"># map()高阶函数，用来批量处理函数传参</span></span><br><span class="line">        pool.<span class="built_in">map</span>(self.parse_page, url_list)</span><br><span class="line">        <span class="comment"># 关闭线程池</span></span><br><span class="line">        pool.close()</span><br><span class="line">        <span class="comment"># 阻塞主线程，等待子线程结束</span></span><br><span class="line">        pool.join()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> self.data_queue.empty():</span><br><span class="line">            <span class="built_in">print</span> self.data_queue.get()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span> self.num</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    douban = DoubanSpider()</span><br><span class="line">    start = time.time()</span><br><span class="line">    douban.main()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;[INFO]: Useing time %f seconds.&quot;</span> % (time.time() - start)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas</summary>
      
    
    
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>爬虫基础篇——之单线程爬虫</title>
    <link href="http://example.com/2021/09/07/%E7%88%AC%E8%99%AB/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%88%AC%E8%99%AB%E2%80%94%E4%B9%8B%E8%B1%86%E7%93%A3%E7%88%AC%E5%8F%96/"/>
    <id>http://example.com/2021/09/07/%E7%88%AC%E8%99%AB/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%88%AC%E8%99%AB%E2%80%94%E4%B9%8B%E8%B1%86%E7%93%A3%E7%88%AC%E5%8F%96/</id>
    <published>2021-09-07T11:34:43.245Z</published>
    <updated>2021-09-07T11:41:21.811Z</updated>
    
    <content type="html"><![CDATA[<p>多线程爬虫案例：</p><p>栗子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># 日期：2021年9月7日19:40:54</span></span><br><span class="line"><span class="comment"># 作者：GeraTear</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> threading</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanSpider</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.data_queue = Queue.Queue()</span><br><span class="line">        self.base_url = <span class="string">&quot;http://movie.douban.com/top250?start=&quot;</span></span><br><span class="line">        self.headers = &#123;<span class="string">&quot;User-Agent&quot;</span> : <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko&quot;</span>&#125;</span><br><span class="line">        self.num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_page</span>(<span class="params">self, url</span>):</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;[INFO]: 正在抓取 %s &quot;</span> % url</span><br><span class="line">        html = requests.get(url, headers = self.headers).content</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> html</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_page</span>(<span class="params">self, url</span>):</span></span><br><span class="line">        html = self.load_page(url)</span><br><span class="line">        html_obj = etree.HTML(html)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 当前页面的所有电影结点的列表</span></span><br><span class="line">        node_list = html_obj.xpath(<span class="string">&quot;//div[@class=&#x27;info&#x27;]&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 迭代每个结点，进行取值</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> node_list:</span><br><span class="line">            <span class="comment"># 电影标题</span></span><br><span class="line">            title = node.xpath(<span class="string">&quot;.//span[@class=&#x27;title&#x27;]/text()&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># 电影评分</span></span><br><span class="line">            score = node.xpath(<span class="string">&quot;.//span[@class=&#x27;rating_num&#x27;]/text()&quot;</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            self.data_queue.put(score + <span class="string">&quot;\t&quot;</span> + title)</span><br><span class="line">            self.num += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">self</span>):</span></span><br><span class="line">        url_list = [self.base_url + <span class="built_in">str</span>(num) <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">225</span> + <span class="number">1</span>, <span class="number">25</span>)]</span><br><span class="line">        <span class="comment"># for url in url_list:</span></span><br><span class="line">        <span class="comment">#     self.parse_page(url)</span></span><br><span class="line"></span><br><span class="line">        thread_list = []</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> url_list:</span><br><span class="line">            <span class="comment"># 创建一个线程,并指定执行的任务</span></span><br><span class="line">           thread = threading.Thread(target= self.parse_page,args= [url])</span><br><span class="line">           thread.start()</span><br><span class="line">           thread_list.append(thread)</span><br><span class="line">            <span class="comment">#让主线程阻塞,等待所有的子线程结束,再继续执行</span></span><br><span class="line">        <span class="keyword">for</span> thread <span class="keyword">in</span> thread_list:</span><br><span class="line">            thread.join()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> self.data_queue.empty():</span><br><span class="line">            <span class="built_in">print</span> self.data_queue.get()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span> self.num</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    douban = DoubanSpider()</span><br><span class="line">    start = time.time()</span><br><span class="line">    douban.main()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;[INFO]: Useing time %f seconds.&quot;</span> % (time.time() - start)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;多线程爬虫案例：&lt;/p&gt;
&lt;p&gt;栗子：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;l</summary>
      
    
    
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>爬虫基础篇——之单线程爬虫</title>
    <link href="http://example.com/2021/09/07/%E7%88%AC%E8%99%AB/%E5%8D%95%E7%BA%BF%E7%A8%8B%E7%88%AC%E8%99%AB%E2%80%94%E4%B9%8B%E8%B1%86%E7%93%A3%E7%88%AC%E5%8F%96/"/>
    <id>http://example.com/2021/09/07/%E7%88%AC%E8%99%AB/%E5%8D%95%E7%BA%BF%E7%A8%8B%E7%88%AC%E8%99%AB%E2%80%94%E4%B9%8B%E8%B1%86%E7%93%A3%E7%88%AC%E5%8F%96/</id>
    <published>2021-09-07T11:18:37.531Z</published>
    <updated>2021-09-07T11:18:08.515Z</updated>
    
    <content type="html"><![CDATA[<p>单线程爬虫案例：</p><p>栗子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment"># 日期：2021年9月7日19:14:47</span></span><br><span class="line"><span class="comment"># 作者：GeraTear</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> Queue</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DoubanSpider</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.data_queue = Queue.Queue()</span><br><span class="line">        self.base_url = <span class="string">&quot;http://movie.douban.com/top250?start=&quot;</span></span><br><span class="line">        self.headers = &#123;<span class="string">&quot;User-Agent&quot;</span> : <span class="string">&quot;Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko&quot;</span>&#125;</span><br><span class="line">        self.num = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">load_page</span>(<span class="params">self, url</span>):</span></span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;[INFO]: 正在抓取 %s &quot;</span> % url</span><br><span class="line">        html = requests.get(url, headers = self.headers).content</span><br><span class="line">        time.sleep(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> html</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_page</span>(<span class="params">self, url</span>):</span></span><br><span class="line">        html = self.load_page(url)</span><br><span class="line">        html_obj = etree.HTML(html)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 当前页面的所有电影结点的列表</span></span><br><span class="line">        node_list = html_obj.xpath(<span class="string">&quot;//div[@class=&#x27;info&#x27;]&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 迭代每个结点，进行取值</span></span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> node_list:</span><br><span class="line">            <span class="comment"># 电影标题</span></span><br><span class="line">            title = node.xpath(<span class="string">&quot;.//span[@class=&#x27;title&#x27;]/text()&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># 电影评分</span></span><br><span class="line">            score = node.xpath(<span class="string">&quot;.//span[@class=&#x27;rating_num&#x27;]/text()&quot;</span>)[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            self.data_queue.put(score + <span class="string">&quot;\t&quot;</span> + title)</span><br><span class="line">            self.num += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">self</span>):</span></span><br><span class="line">        url_list = [self.base_url + <span class="built_in">str</span>(num) <span class="keyword">for</span> num <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">225</span> + <span class="number">1</span>, <span class="number">25</span>)]</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> url_list:</span><br><span class="line">            self.parse_page(url)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> self.data_queue.empty():</span><br><span class="line">            <span class="built_in">print</span> self.data_queue.get()</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span> self.num</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    douban = DoubanSpider()</span><br><span class="line">    start = time.time()</span><br><span class="line">    douban.main()</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;[INFO]: Useing time %f seconds.&quot;</span> % (time.time() - start)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;单线程爬虫案例：&lt;/p&gt;
&lt;p&gt;栗子：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;l</summary>
      
    
    
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>爬虫基础篇——之Cookie</title>
    <link href="http://example.com/2021/09/06/%E7%88%AC%E8%99%AB/%E4%BD%BF%E7%94%A8Cookie%E8%BF%9B%E8%A1%8C%E7%BD%91%E7%AB%99%E7%99%BB%E5%BD%95%E7%8A%B6%E6%80%81%E4%BF%9D%E6%8C%81/"/>
    <id>http://example.com/2021/09/06/%E7%88%AC%E8%99%AB/%E4%BD%BF%E7%94%A8Cookie%E8%BF%9B%E8%A1%8C%E7%BD%91%E7%AB%99%E7%99%BB%E5%BD%95%E7%8A%B6%E6%80%81%E4%BF%9D%E6%8C%81/</id>
    <published>2021-09-06T04:39:06.293Z</published>
    <updated>2021-09-06T05:35:11.795Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Cookie"><a href="#Cookie" class="headerlink" title="Cookie"></a>Cookie</h2><p>HTTP是无状态的面向连接的协议，服务器和客户端的交互仅限于请求/响应过程，结束之后便断开，在下一次请求时，服务器会认为新的客户端。为了维护他们之间的链接，让服务器知道这是之前某个用户发送的请求，则必须在一个地方保存客户端的信息。</p><p><strong>Cookie</strong>：通过在 客户端 记录的信息确定用户的身份。</p><p><strong>Session</strong>：通过在 服务器端 记录的信息确定用户的身份。</p><p>Cookie 是指某些网站服务器为了辨别用户身份和进行Session跟踪，而储存在用户浏览器上的文本文件，Cookie可以保持登录信息到用户下次与服务器的会话</p><p>栗子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line">header = &#123;<span class="string">&quot;User-Agent&quot;</span>:<span class="string">&quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36&quot;</span>,</span><br><span class="line">          <span class="string">&quot;Cookie&quot;</span>:<span class="string">&quot;uuid_tt_dd=-8029438850993860835_20171017; __gads=ID=e106ad9f58fb9c92-222de2144ccb0056:T=1630497961:RT=1630497961:S=ALNI_MbrSsuP1ydPHAyM2QuDx92EGyBppg; csrfToken=6bkjwDuaspuWKypI7yiqsScg; c_first_ref=default; c_first_page=https%3A//www.csdn.net/; dc_sid=a3f8fa77c2693870b4356b7fb76094a8; SESSION=e3766f16-2bc4-4fe5-b8ec-fedfee4e0e1c; ssxmod_itna=Yq0hDKAIqAxIox+xBPwKx9BtGC8tQGkKE0bI+DBdSeiNDnD8x7YDvI+OiIQTeThiDahqE4hh0fxjbhnrfxQ8zSeDIDmKDyDW5DlDDbH47DlPKKaIDBYDhxG=yHy4A6X5DB4wXDzdMHDTxGafxiitDDrDjuHDY9FHgKDmxGtsxGWDWWa7bBs7UBHaaaGDnW+EW3Dy2KDRxiOD0RHDmWFDQ91TePWA10e/IDWm0hqrBDqqWxqCG2DwBGqTB0Doi=qh024AlM95DDW=Ld34D===; ssxmod_itna2=Yq0hDKAIqAxIox+xBPwKx9BtGC8tQGkKE0bD8MekBDGXmxQGaK7KmH1x8hT/itbYt6nOu5i47YSAvUYDwehYdOSbikBNvRjY1iQOG4d=4qUDatux6x6+ldeiK6CCLDygsxI71gengS35Y0=OSoAF/g3FbljR8lKdYSEs+BN1FLbpj+KgISA5cgIviWWiyjNN=pn=w7=u3cR0iwY7ykoGA2hou=wNLQe+YAyGgmn+Tcy+SWgk/xmGcSotCYSfju8QEr36Fw2vnOKKMI6Hf8Bx4KCMIM31+w2cFzDXf8rHIgZ6kCLXN+x41q6rXF7KZZpFYiu0Yq3U9A0REPMnIlhU9jUR=QvlmxjdgxX1OiX6dErwKQGTDG2+xxUBN0DqSr4mD=0id1uTGEQEoqtDDFqD+1DxD===; UserName=qq_35681646; UserInfo=cbd262effcd8456a94bf003541ccc6a8; UserToken=cbd262effcd8456a94bf003541ccc6a8; UserNick=%E5%8D%83%7E%E8%91%89; AU=DCE; UN=qq_35681646; BT=1630904317563; p_uid=U010000; firstDie=1; log_Id_click=37; c_pref=https%3A//blog.csdn.net/qq_35681646; c_ref=https%3A//i.csdn.net/; c_segment=9; dc_session_id=10_1630904353724.702297; c_page_id=default; dc_tos=qyzy16; log_Id_pv=25; Hm_lvt_6bcd52f51e9b3dce32bec4a3997715ac=1630497988,1630499691,1630501187,1630904360; Hm_lpvt_6bcd52f51e9b3dce32bec4a3997715ac=1630904589; Hm_up_6bcd52f51e9b3dce32bec4a3997715ac=%7B%22islogin%22%3A%7B%22value%22%3A%221%22%2C%22scope%22%3A1%7D%2C%22isonline%22%3A%7B%22value%22%3A%221%22%2C%22scope%22%3A1%7D%2C%22isvip%22%3A%7B%22value%22%3A%220%22%2C%22scope%22%3A1%7D%2C%22uid_%22%3A%7B%22value%22%3A%22qq_35681646%22%2C%22scope%22%3A1%7D%7D; Hm_ct_6bcd52f51e9b3dce32bec4a3997715ac=6525*1*-8029438850993860835_20171017!5744*1*qq_35681646; log_Id_view=36&quot;</span></span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">request = urllib2.Request(<span class="string">&quot;https://www.csdn.net/?spm=1010.2135.3001.4476&quot;</span>,headers= header)</span><br><span class="line"></span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> response.read()</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Cookie&quot;&gt;&lt;a href=&quot;#Cookie&quot; class=&quot;headerlink&quot; title=&quot;Cookie&quot;&gt;&lt;/a&gt;Cookie&lt;/h2&gt;&lt;p&gt;HTTP是无状态的面向连接的协议，服务器和客户端的交互仅限于请求/响应过程，结束之后便断开，在下一次请求时，</summary>
      
    
    
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>爬虫基础篇——之请求报头的添加或修改</title>
    <link href="http://example.com/2021/09/04/%E7%88%AC%E8%99%AB/%E8%AF%B7%E6%B1%82%E6%8A%A5%E5%A4%B4%E7%9A%84%E6%B7%BB%E5%8A%A0%E6%88%96%E4%BF%AE%E6%94%B9/"/>
    <id>http://example.com/2021/09/04/%E7%88%AC%E8%99%AB/%E8%AF%B7%E6%B1%82%E6%8A%A5%E5%A4%B4%E7%9A%84%E6%B7%BB%E5%8A%A0%E6%88%96%E4%BF%AE%E6%94%B9/</id>
    <published>2021-09-04T13:13:30.963Z</published>
    <updated>2021-09-04T13:18:13.306Z</updated>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment">#   作者:轩</span></span><br><span class="line"><span class="comment">#   日期:2021年9月4日</span></span><br><span class="line"><span class="comment">#   说明:User_agnet请求报头的添加或修改</span></span><br><span class="line"><span class="keyword">import</span>  urllib2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 请求报头, 字典类型</span></span><br><span class="line">headers =&#123;<span class="string">&quot;User-Agent&quot;</span>: <span class="string">&quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将url和headers 封装为请求对象</span></span><br><span class="line">request = urllib2.Request(<span class="string">&quot;http://www.baidu.com/&quot;</span>,headers= headers )</span><br><span class="line"></span><br><span class="line"><span class="comment"># get_header()获取指定请求报头的值,字符串只能第一个字母大写,后面的必须全部小写</span></span><br><span class="line"><span class="built_in">print</span> request.get_header(<span class="string">&quot;User-agent&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> request.get_header(<span class="string">&quot;Connection&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add_header() 添加/修改一个请求报头</span></span><br><span class="line">request.add_header(<span class="string">&quot;Connection&quot;</span>,<span class="string">&quot;keep-alive&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> request.get_header(<span class="string">&quot;Connection&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># urlopen() 发送请求对象,返回服务器的响应</span></span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print response.read()</span></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas</summary>
      
    
    
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>爬虫基础篇——之百度贴吧爬取</title>
    <link href="http://example.com/2021/09/04/%E7%88%AC%E8%99%AB/%E7%99%BE%E5%BA%A6%E8%B4%B4%E5%90%A7%E7%88%AC%E5%8F%96/"/>
    <id>http://example.com/2021/09/04/%E7%88%AC%E8%99%AB/%E7%99%BE%E5%BA%A6%E8%B4%B4%E5%90%A7%E7%88%AC%E5%8F%96/</id>
    <published>2021-09-04T12:33:06.709Z</published>
    <updated>2021-09-04T12:39:50.778Z</updated>
    
    <content type="html"><![CDATA[<p>百度贴吧爬虫案例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#-*- coding:utf-8 -*-</span></span><br><span class="line"><span class="comment">#   作者:轩</span></span><br><span class="line"><span class="comment">#   日期:2021年9月3日</span></span><br><span class="line"><span class="comment">#   说明: 百度贴吧爬虫</span></span><br><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_page</span>(<span class="params">url,filename</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    发送请求,返回响应</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;[INFO]正在爬取 %...&quot;</span> % filename</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = urllib2.urlopen(url)</span><br><span class="line">        <span class="keyword">return</span> response.read()</span><br><span class="line">    <span class="keyword">except</span>:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;[ERRoR]:%s 爬取失败&quot;</span> % filename</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_page</span>(<span class="params">html,filename</span>):</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;[info] 正在保存 %s ...&quot;</span>% filename</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(filename,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(html)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_work</span>(<span class="params">tieba_name,start_page,end_page</span>):</span></span><br><span class="line">    base_url =<span class="string">&quot;http://tieba.baidu.com/f?&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> page <span class="keyword">in</span> <span class="built_in">range</span>(start_page,end_page +<span class="number">1</span>):</span><br><span class="line">        pn = (page -<span class="number">1</span>) *<span class="number">50</span></span><br><span class="line"></span><br><span class="line">        dict_kw =&#123;<span class="string">&quot;kw&quot;</span>:tieba_name,<span class="string">&quot;pn&quot;</span>:pn&#125;</span><br><span class="line">        str_kw = urllib.urlencode(dict_kw)</span><br><span class="line"></span><br><span class="line">        full_url = base_url +str_kw</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span> full_url</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;\n爬取完成,谢谢使用&quot;</span></span><br><span class="line"><span class="keyword">if</span> __name__== <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    tieba_name = raw_input(<span class="string">&quot;请输入需要的爬取的贴吧名:&quot;</span>)</span><br><span class="line">    start_page = <span class="built_in">int</span>(raw_input(<span class="string">&quot;请输入爬取的起始页&quot;</span>))</span><br><span class="line">    end_page = <span class="built_in">int</span>(raw_input(<span class="string">&#x27;请输入爬取的结束页&#x27;</span>))</span><br><span class="line">    start_work(tieba_name,start_page,end_page)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;百度贴吧爬虫案例&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/spa</summary>
      
    
    
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>爬虫基础篇—之User-Agent</title>
    <link href="http://example.com/2021/09/03/%E7%88%AC%E8%99%AB/User-Agent/"/>
    <id>http://example.com/2021/09/03/%E7%88%AC%E8%99%AB/User-Agent/</id>
    <published>2021-09-03T13:21:32.000Z</published>
    <updated>2021-09-04T05:55:55.329Z</updated>
    
    <content type="html"><![CDATA[<p>Urllib2默认的User-Agent 头为：Python-Urllib/x.y (python-urllib/2.7)</p><p>伪装成一个合法的身份，用不同浏览器发送请求时，会有不同的User-Agnet报头</p><p>栗子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line">url = <span class="string">&#x27;http://www.bixuan.xyz&#x27;</span></span><br><span class="line"><span class="comment"># 添加 User-Agent报头</span></span><br><span class="line">User_agent =&#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0(compatible;MSIE9.0;Windows NT6.1;Trident/5.0)&#x27;</span>&#125;</span><br><span class="line">request =urllib2.Request(url,headers = User_agent)</span><br><span class="line"><span class="comment"># 向服务器发送这个请求</span></span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line">html = response.read()</span><br><span class="line"><span class="built_in">print</span> html</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Urllib2默认的User-Agent 头为：Python-Urllib/x.y (python-urllib/2.7)&lt;/p&gt;
&lt;p&gt;伪装成一个合法的身份，用不同浏览器发送请求时，会有不同的User-Agnet报头&lt;/p&gt;
&lt;p&gt;栗子：&lt;/p&gt;
&lt;figure clas</summary>
      
    
    
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>爬虫基础篇—之Header</title>
    <link href="http://example.com/2021/09/03/%E7%88%AC%E8%99%AB/Heder/"/>
    <id>http://example.com/2021/09/03/%E7%88%AC%E8%99%AB/Heder/</id>
    <published>2021-09-03T13:21:32.000Z</published>
    <updated>2021-09-03T13:53:55.200Z</updated>
    
    <content type="html"><![CDATA[<p>在发送HTTP Request 中添加特定的Header，来构造一个完整的HTTP请求消息</p><p>可以通过调用Request.add_header()添加/修改</p><p>也可以用Request.get_header()</p><p>添加一个特定header</p><p>栗子:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line">url =<span class="string">&quot;http://www.bixuan.xyz&quot;</span></span><br><span class="line"><span class="comment"># 添加User-Agent报头</span></span><br><span class="line">User_agent =&#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;Mozilla/5.0(compatible;MSIE9.0;Windows NT6.1;Trident/5.0)&#x27;</span>&#125;</span><br><span class="line">request = urllib2.Request(url,headers = User_agent)</span><br><span class="line"><span class="comment"># 通过调用Request.add_header()添加/修改header</span></span><br><span class="line">request.add_header(<span class="string">&#x27;Connection&#x27;</span>,<span class="string">&#x27;keep-alive&#x27;</span>)</span><br><span class="line"><span class="comment"># 通过调用Request.get_header()查看header信息</span></span><br><span class="line"><span class="comment"># Request.get_geader(head_name = &#x27;Connection&#x27;)</span></span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line"><span class="comment"># 可以查看响应状态码</span></span><br><span class="line"><span class="built_in">print</span> response.code</span><br><span class="line">html = response.read()</span><br><span class="line"><span class="built_in">print</span> html</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">随机添加/修改User-Agent</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line">url = <span class="string">&quot;http://www.bixuan.xyz&quot;</span></span><br><span class="line"></span><br><span class="line">ua_list = [</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.1 (KHTML, like Gecko) Chrome/22.0.1207.1 Safari/537.1&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (X11; CrOS i686 2268.111.0) AppleWebKit/536.11 (KHTML, like Gecko) Chrome/20.0.1132.57 Safari/536.11&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1092.0 Safari/536.6&quot;</span>,</span><br><span class="line">    <span class="string">&quot;Mozilla/5.0 (Windows NT 6.1) AppleWebKit/536.6 (KHTML, like Gecko) Chrome/20.0.1090.0 Safari/536.6&quot;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">user_agent = random.choice(ua_list)</span><br><span class="line"></span><br><span class="line">request = urllib2.Request(url)</span><br><span class="line"></span><br><span class="line"><span class="comment">#也可以通过调用Request.add_header() 添加/修改一个特定的header</span></span><br><span class="line">request.add_header(<span class="string">&quot;User-Agent&quot;</span>, user_agent)</span><br><span class="line"></span><br><span class="line"><span class="comment"># get_header()的字符串参数，第一个字母大写，后面的全部小写</span></span><br><span class="line">request.get_header(<span class="string">&quot;User-agent&quot;</span>)</span><br><span class="line"></span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line"></span><br><span class="line">html = response.read()</span><br><span class="line"><span class="built_in">print</span> html</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在发送HTTP Request 中添加特定的Header，来构造一个完整的HTTP请求消息&lt;/p&gt;
&lt;p&gt;可以通过调用Request.add_header()添加/修改&lt;/p&gt;
&lt;p&gt;也可以用Request.get_header()&lt;/p&gt;
&lt;p&gt;添加一个特定header&lt;</summary>
      
    
    
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>爬虫基础篇—之Get和Post方法</title>
    <link href="http://example.com/2021/09/03/%E7%88%AC%E8%99%AB/Get%E5%92%8CPost%E6%96%B9%E6%B3%95/"/>
    <id>http://example.com/2021/09/03/%E7%88%AC%E8%99%AB/Get%E5%92%8CPost%E6%96%B9%E6%B3%95/</id>
    <published>2021-09-03T13:21:32.000Z</published>
    <updated>2021-09-06T02:53:54.857Z</updated>
    
    <content type="html"><![CDATA[<h2 id="urllib2默认只支持HTTP-HTTPS的GET和POST方法"><a href="#urllib2默认只支持HTTP-HTTPS的GET和POST方法" class="headerlink" title="urllib2默认只支持HTTP/HTTPS的GET和POST方法"></a>urllib2默认只支持HTTP/HTTPS的<code>GET</code>和<code>POST</code>方法</h2><h3 id="URL编码转换：urllib的urlencode"><a href="#URL编码转换：urllib的urlencode" class="headerlink" title="URL编码转换：urllib的urlencode()"></a>URL编码转换：urllib的urlencode()</h3><p>Urlencode方法用来产生get查询字符串，而urllib2则没有（这是urllib和urllib2经常一起使用主要原因）</p><p>Urlencode()函数，将key：value 键值对，转换成’key = value’ 这样的字符串</p><p>urllib 的Unquote()函数</p><p>栗子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import urllib</span><br><span class="line">word = &#123;&#x27;wd&#x27;:&#x27;轩轩&#x27;&#125;</span><br><span class="line">urllib.urlencode(word)</span><br><span class="line">#运行结果：wd =%DO%F9DO%F9%DO%F9%DO%F9</span><br><span class="line">print urllib.unquote(&#x27;wd=%DO%F9%DO%F9 )</span><br><span class="line">#运行结果：wd = 轩轩</span><br></pre></td></tr></table></figure><h5 id="一般HTTP请求提交数据，需要编码成-URL编码格式，然后做为url的一部分，或者作为参数传到Request对象中。"><a href="#一般HTTP请求提交数据，需要编码成-URL编码格式，然后做为url的一部分，或者作为参数传到Request对象中。" class="headerlink" title="一般HTTP请求提交数据，需要编码成 URL编码格式，然后做为url的一部分，或者作为参数传到Request对象中。"></a>一般HTTP请求提交数据，需要编码成 URL编码格式，然后做为url的一部分，或者作为参数传到Request对象中。</h5><p>Get方式</p><p>get请求一般用于服务器获取数据 ，比如用百度搜索  轩轩: <a href="https://www.baidu.com/">https://www.baidu.com/</a>? wd = 轩轩</p><p>浏览器的url跳转成：<a href="https://www.baidu.com/s%EF%BC%9Fwd">https://www.baidu.com/s？wd</a> =轩轩</p><p><a href="http://www.baidu.com/s">http://www.baidu.com/s</a>? wd=%DO%F9%D%F9</p><p><a href="http://www.baidu.com/S">http://www.baidu.com/S</a>? 之后出现长字符串，其中就包含要查询的关键字，于是尝试用默认get方式发送请求</p><p>例子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line">url = <span class="string">&#x27;http://www.baidu.com/S&#x27;</span></span><br><span class="line">word = &#123;<span class="string">&#x27;wd&#x27;</span>:<span class="string">&#x27;轩轩&#x27;</span>&#125;</span><br><span class="line">word = urllib.urlencode(word) <span class="comment">#转换成url编码格式（字符串）</span></span><br><span class="line">newurl = url +<span class="string">&#x27;?&#x27;</span>+word  <span class="comment"># url首个分隔符就是？</span></span><br><span class="line">headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>:<span class="string">&#x27;&quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36&quot;&#x27;</span>&#125;</span><br><span class="line">request = urllib2.Request(newurl, headers=headers)</span><br><span class="line"></span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> response.read()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>Post方式：</p><p>Request请求对象的里有data参数，它就是用在POST里的，我们要传送的数据就是这个参数data，data是一个字典，里面要匹配键值对。</p><p>Post请求向服务器发送请求数据并不是在url里，Post请求一定要抓包。</p><ul><li>POST方式则不会在网址上显示所有的参数，服务器端用Request.Form获取提交的数据，在Form提交的时候。但是HTML代码里如果不指定 method 属性，则默认为GET请求，Form中提交的数据将会附加在url之后，以<code>?</code>分开与url分开。</li><li>表单数据可以作为 URL 字段（method=”get”）或者 HTTP POST （method=”post”）的方式来发送。</li><li>GET方式是直接以链接形式访问，链接中包含了所有的参数，服务器端用Request.QueryString获取变量的值。如果包含了密码的话是一种不安全的选择，不过你可以直观地看到自己提交了什么内容。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;urllib2默认只支持HTTP-HTTPS的GET和POST方法&quot;&gt;&lt;a href=&quot;#urllib2默认只支持HTTP-HTTPS的GET和POST方法&quot; class=&quot;headerlink&quot; title=&quot;urllib2默认只支持HTTP/HTTPS的GET</summary>
      
    
    
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>爬虫基础篇—之User-Agent</title>
    <link href="http://example.com/2021/09/03/%E7%88%AC%E8%99%AB/%E5%A4%84%E7%90%86HTTPS%E8%AF%B7%E6%B1%82%20SSL%E8%AF%81%E4%B9%A6%E9%AA%8C%E8%AF%81/"/>
    <id>http://example.com/2021/09/03/%E7%88%AC%E8%99%AB/%E5%A4%84%E7%90%86HTTPS%E8%AF%B7%E6%B1%82%20SSL%E8%AF%81%E4%B9%A6%E9%AA%8C%E8%AF%81/</id>
    <published>2021-09-03T13:21:32.000Z</published>
    <updated>2021-09-06T03:18:42.872Z</updated>
    
    <content type="html"><![CDATA[<p>urllib2可以为HTTP请求验证SSL证书，如果网站的SSL证书是经过CA认证的，则能正常访问。</p><p>如：<a href="https://www.baidu.com/">https://www.baidu.com</a></p><p>忽略12306网站数字证书认证</p><p>栗子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line"><span class="comment"># 1.表示忽略网站的数字证书认证</span></span><br><span class="line">context = ssl._create_unverified_context()</span><br><span class="line">url = <span class="string">&quot;https://www.12306.cn/mormhweb/&quot;</span></span><br><span class="line"></span><br><span class="line">headers = &#123;<span class="string">&quot;User-Agent&quot;</span>:<span class="string">&quot;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line">request = urllib2.Request(url,headers= headers)</span><br><span class="line"><span class="comment"># 2.发送请求，在urlopen（）添加context</span></span><br><span class="line">response = urllib2.urlopen(request,context=context)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> response.read()</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;urllib2可以为HTTP请求验证SSL证书，如果网站的SSL证书是经过CA认证的，则能正常访问。&lt;/p&gt;
&lt;p&gt;如：&lt;a href=&quot;https://www.baidu.com/&quot;&gt;https://www.baidu.com&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;忽略12306网站数字</summary>
      
    
    
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>爬虫基础篇—之Hanlder处理器和自定义opener</title>
    <link href="http://example.com/2021/09/03/%E7%88%AC%E8%99%AB/Handler%E5%A4%84%E7%90%86%E5%99%A8%E5%92%8C%E8%87%AA%E5%AE%9A%E4%B9%89Opener/"/>
    <id>http://example.com/2021/09/03/%E7%88%AC%E8%99%AB/Handler%E5%A4%84%E7%90%86%E5%99%A8%E5%92%8C%E8%87%AA%E5%AE%9A%E4%B9%89Opener/</id>
    <published>2021-09-03T13:21:32.000Z</published>
    <updated>2021-09-06T03:41:38.230Z</updated>
    
    <content type="html"><![CDATA[<p>opener 是urllib2.Oopener是模块构建好的</p><p>基本的Urlopen()方法 不支持代理、Cookie等其它的HTTP/HTTPS高级功能</p><p>要支持这些功能：</p><p>1.使用相关的Handler 处理器来创建特定功能的处理器对象</p><p>2.然后通过Urllib2.buid_open()方法使用这些处理器对象</p><p>3.使用自定义的Opener对象，调用Open()方法发送请求</p><p>如果程序里的所有请求 都是使用自定义的Opener对象定义为全局Opener，表示如果之后凡是调用Urlopen，都将使用这个Opener</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line">request = urllib2.Request(<span class="string">&quot;http://www.baidu.com/&quot;</span>)</span><br><span class="line"><span class="comment"># 1.创建一个能够处理Http请求 处理器对象</span></span><br><span class="line">http_handler = urllib2.HTTPHandler(debuglevel = <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 2.使用处理器对象，创建opener对象</span></span><br><span class="line">opener = urllib2.build_opener(http_handler)</span><br><span class="line"></span><br><span class="line">response = opener.<span class="built_in">open</span>(request)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;opener 是urllib2.Oopener是模块构建好的&lt;/p&gt;
&lt;p&gt;基本的Urlopen()方法 不支持代理、Cookie等其它的HTTP/HTTPS高级功能&lt;/p&gt;
&lt;p&gt;要支持这些功能：&lt;/p&gt;
&lt;p&gt;1.使用相关的Handler 处理器来创建特定功能的处理器对</summary>
      
    
    
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>爬虫基础篇—之ProxyHandler(代理设置)</title>
    <link href="http://example.com/2021/09/03/%E7%88%AC%E8%99%AB/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E2%80%94%E4%B9%8BProxyHandler(%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE)/"/>
    <id>http://example.com/2021/09/03/%E7%88%AC%E8%99%AB/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E2%80%94%E4%B9%8BProxyHandler(%E4%BB%A3%E7%90%86%E8%AE%BE%E7%BD%AE)/</id>
    <published>2021-09-03T13:21:32.000Z</published>
    <updated>2021-09-06T04:30:12.256Z</updated>
    
    <content type="html"><![CDATA[<p>使用代理IP,   是爬虫/ 反爬虫通常最好用的第二种方式</p><p>设置代理服务器，每隔一段时间换一个代理，就算IP被禁止，可以换个IP继续爬取</p><p>urllib2中通过ProxyHandler来设置使用代理服务器</p><p>栗子：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line"><span class="comment"># 免费代理用法</span></span><br><span class="line"><span class="comment"># proxy = &#123;&quot;http&quot;:&quot;IP:端口号&quot;&#125;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 私密代理(需要进行账户验证) </span></span><br><span class="line"><span class="comment"># 注意：如果账号密码或者IP：端口出错，程序会报错</span></span><br><span class="line"><span class="comment"># 如果协议写错，那么不使用这个代理，相当于proxy = &#123;&#125;</span></span><br><span class="line">proxy = &#123;<span class="string">&quot;http&quot;</span>:<span class="string">&quot;账户名:密码@IP:端口号&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建一个代理处理器对象,参数就是设置的可用代理</span></span><br><span class="line">proxy_handler=urllib2.ProxyHandler(proxy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用这个代理处理器对象,构建一个opener对象,这个opener发送请求时,就会附带这个代理</span></span><br><span class="line">opener = urllib2.build_opener(proxy_handler)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 发送请求</span></span><br><span class="line">response = opener.<span class="built_in">open</span>(<span class="string">&quot;http://wwww.baidu.com/&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> response.read()</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;使用代理IP,   是爬虫/ 反爬虫通常最好用的第二种方式&lt;/p&gt;
&lt;p&gt;设置代理服务器，每隔一段时间换一个代理，就算IP被禁止，可以换个IP继续爬取&lt;/p&gt;
&lt;p&gt;urllib2中通过ProxyHandler来设置使用代理服务器&lt;/p&gt;
&lt;p&gt;栗子：&lt;/p&gt;
&lt;figur</summary>
      
    
    
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>爬虫基础篇——之Urllib2模块</title>
    <link href="http://example.com/2021/09/03/%E7%88%AC%E8%99%AB/Urllib2%E6%A8%A1%E5%9D%97/"/>
    <id>http://example.com/2021/09/03/%E7%88%AC%E8%99%AB/Urllib2%E6%A8%A1%E5%9D%97/</id>
    <published>2021-09-02T22:49:38.772Z</published>
    <updated>2021-09-03T13:03:15.250Z</updated>
    
    <content type="html"><![CDATA[<p>urllib2模块用于网络爬虫、抓取网页，urllib2支持Python2</p><p>Python3中Urllib2被改为Urllib.request</p><p>模块安装：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip intsall urllib2</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入模块</span></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="comment"># urllib2.urlopen 向指定的URL发送请求，并返回服务器响应的类文件对象</span></span><br><span class="line">respnse = urllib2.urlopen(<span class="string">&#x27;http://www.bixuan.xyz&#x27;</span>)</span><br><span class="line"><span class="comment"># read()方法读取文件全部内容，返回字符串</span></span><br><span class="line">html =response.read()</span><br><span class="line"><span class="built_in">print</span> html</span><br></pre></td></tr></table></figure><p>栗子2：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入urllib2模块</span></span><br><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"><span class="comment"># url作为Request()方法的参数，构造并返回一个Request对象</span></span><br><span class="line">request = urllib2.Request(<span class="string">&#x27;http://www.bixuan.xyz&#x27;</span>)</span><br><span class="line"><span class="comment"># request对象作为urlopen()方法参数，发送给服务器并接收响应</span></span><br><span class="line">response = urllib2.urlopen(request)</span><br><span class="line"><span class="comment"># 读取文件</span></span><br><span class="line">html = response.read()</span><br><span class="line"><span class="built_in">print</span> html</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;urllib2模块用于网络爬虫、抓取网页，urllib2支持Python2&lt;/p&gt;
&lt;p&gt;Python3中Urllib2被改为Urllib.request&lt;/p&gt;
&lt;p&gt;模块安装：&lt;/p&gt;
&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;t</summary>
      
    
    
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>爬虫基础篇——之理论篇</title>
    <link href="http://example.com/2021/08/29/%E7%88%AC%E8%99%AB/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E2%80%94%E4%B9%8B%E7%90%86%E8%AE%BA%E7%AF%87/"/>
    <id>http://example.com/2021/08/29/%E7%88%AC%E8%99%AB/%E7%88%AC%E8%99%AB%E5%9F%BA%E7%A1%80%E7%AF%87%E2%80%94%E4%B9%8B%E7%90%86%E8%AE%BA%E7%AF%87/</id>
    <published>2021-08-29T09:38:37.686Z</published>
    <updated>2021-07-09T04:58:50.906Z</updated>
    
    <content type="html"><![CDATA[<p>1.网络爬虫又称网络蜘蛛、网络机器人是一种按照一定的规则，自动抓取万维网信息的程序或脚本</p><p>2.搜索引擎就是通用网络爬虫，如：google、百度（通用爬虫）     通用爬虫具有一定的局限性<br>3.网络爬虫类型：<strong>通用网络爬虫</strong>、<strong>聚集网络爬虫</strong>、<strong>分布式网络爬</strong><br>4.爬虫主要步骤：</p><ul><li><p>1.对爬取目标的 url 定义</p></li><li><p>2.对网页数据分析与协议获取对应 HTML</p></li><li><p>3.对页面进行提取 HTML 页面有价值的数据<br><img "" class="lazyload placeholder" data-original="https://img-blog.csdnimg.cn/20190422003146166.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjU5ODEy,size_16,color_FFFFFF,t_70" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="爬虫流程图"></p></li></ul><ol start="5"><li> 通用爬虫需要遵守一定规则（nofollow 协议或 Robots 协议），全称是网络爬虫排除标准</li><li>通用爬虫只能抓取 HTML、PDF、word、wps、XLP、PPT、TXflash、音频、脚本程序</li><li>HTTP 协议（Hyper Text Transfer Protocl，超文本传输协议）是面的规则</li><li>HTTPS 协议（Hypertext Transfer Protocl oVer Secure Socket Laye层（安全套接层）主要用于安全传输协议，在网络传输层进行加密</li></ol><ul><li>HTTP 的端口号：80</li><li>HTTPS 的端口号：443</li></ul><ol start="9"><li>HTTP 请求与响应：浏览器发送请求等待服务器响应并返回数流程图 浏览器 发送请求数据 响应并返回数据<br><img "" class="lazyload placeholder" data-original="https://img-blog.csdnimg.cn/20190422004510653.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="客户端与服务端连接流程图"></li><li>统一资源定位符 URL:如 <a href="http://www.baidu.com:8080/a">http://www.baidu.com:8080/a</a><br><img "" class="lazyload placeholder" data-original="https://img-blog.csdnimg.cn/2019042200484918.png" src="https://img10.360buyimg.com/ddimg/jfs/t1/157667/29/9156/134350/603c6445Ebbc9cabe/41219c5d36d45072.gif" alt="统一资源定位符"></li></ol><p>11.客户端 HTTP 请求：</p><ul><li>浏览器发送一个 HTTP 请求到服务器</li><li>请求格式: 请求行、请求头、空行.请求数据</li><li>GET： http:// <a href="http://www.baidu.com/HTTP/1.1">www.baidu.com/HTTP/1.1</a></li><li>Host:：<a href="http://www.baidu.com/">www.baidu.com</a></li><li>User-Aget: Mozilla/chrome</li><li>Cookie：</li></ul><p>12.HTTP 请求主要分为 get 和 postGet 请求：</p><ul><li>Get请求：是从服务器上获取页面信息</li><li>Post 请求：是向服务器提交数据并获取页面信息</li><li><strong>Get 请求参数都显示在 URL 上，服务器根据请求 URL 的参数产生响的一部分</strong></li><li><strong>Post 请求参数在请求体中，消息长度没有限制而且隐式方式进行在 URL 中，而是在请求体中因此 Get 请求方式不安全，而 Post 请求方式相对来说比较安全</strong></li></ul><p>13.请求报头</p><ul><li>Host（主机和端口号）</li><li>UPgrade-lnsecure-Reuqusts(升级为 HTTPS 请求)</li><li>User-agent(浏览器名称)</li><li>Accept(传输文件类型)</li><li>Referer(页面跳转来源)</li><li>Accept-Encoding(文件编解码格式)</li><li>Accept-Language(语言类型)</li><li>Accept-charset(字符编码)</li><li>CookieContent-Type(Post 数据类型)</li><li>服务端 HTTP 响应</li></ul><p>14.响应报头</p><ul><li>Cache-Control:must-revalidate,no-cache,Private</li><li>Connection:Keep-alive</li><li>Content-Encoding:gzip</li><li>Content-Type:text/html;charset = utf-8</li><li>Date:sun,21 sep 2017.01:06.21 GMT<br>服务器端发送资源时的时间，不同时区在相互请求资源时间混乱，http 协议中发送时间都<br>是 GMT</li><li>Server : Tengine/1.4.6<br>服务器和相对应的版本，只是告诉浏览器服务器的信息</li><li>Transfer-Encoding:chunked</li></ul><ol start="15"><li>响应状态码：</li></ol><ul><li>200:访问成功正常</li><li>404:访问失败，没有找到请求信息</li><li>500:服务器端出现错误，请求未完成</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;1.网络爬虫又称网络蜘蛛、网络机器人是一种按照一定的规则，自动抓取万维网信息的程序或脚本&lt;/p&gt;
&lt;p&gt;2.搜索引擎就是通用网络爬虫，如：google、百度（通用爬虫）     通用爬虫具有一定的局限性&lt;br&gt;3.网络爬虫类型：&lt;strong&gt;通用网络爬虫&lt;/strong&gt;</summary>
      
    
    
    
    
    <category term="爬虫" scheme="http://example.com/tags/%E7%88%AC%E8%99%AB/"/>
    
  </entry>
  
  <entry>
    <title>了解我</title>
    <link href="http://example.com/2021/08/29/%E4%BA%86%E8%A7%A3%E6%88%91/"/>
    <id>http://example.com/2021/08/29/%E4%BA%86%E8%A7%A3%E6%88%91/</id>
    <published>2021-08-29T09:38:37.630Z</published>
    <updated>2021-09-04T05:49:46.830Z</updated>
    
    <content type="html"><![CDATA[<h2 id="博客的初心"><a href="#博客的初心" class="headerlink" title="博客的初心"></a>博客的初心</h2><p>希望记录平时遇到的问题和知识或所思所想！</p><ul><li>其实一直以来喜欢瞎折腾;(Ps):其实我弄水晶头、拉网线、配 IP、装系统、给手机贴膜的技术还算可以的，其它都不行。</li></ul><h2 id="兴趣"><a href="#兴趣" class="headerlink" title="兴趣"></a>兴趣</h2><ul><li>运动：跑步、溜冰、羽毛球都喜欢</li><li>摄影：任何时候都有美好的一瞬间</li><li>唱歌：五音不全的我也能成为麦霸</li><li>哲学：人生是一场无止境的哲学</li><li>音乐：许嵩、轻音乐</li><li>旅行：遇到不一样的人和风景</li><li>读书：历史，专业书籍</li><li>动漫：哆啦A梦、纳米核心、全职高手、末世觉醒等等</li><li>分享：喜欢把自己的经验分享给大家</li><li>DIY：一切皆可创造<h2 id="欢迎留言"><a href="#欢迎留言" class="headerlink" title="欢迎留言"></a>欢迎留言</h2>曾就职于朵莓网络，实习僧一枚。如果有什么建议和想法，都可以和我留言，就算留言未必有回响————By:轩</li><li>电子邮箱：<a href="mailto:&#x47;&#x65;&#x72;&#97;&#84;&#x65;&#97;&#114;&#64;&#x67;&#x6d;&#97;&#105;&#108;&#46;&#x63;&#111;&#x6d;">&#x47;&#x65;&#x72;&#97;&#84;&#x65;&#97;&#114;&#64;&#x67;&#x6d;&#97;&#105;&#108;&#46;&#x63;&#111;&#x6d;</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;博客的初心&quot;&gt;&lt;a href=&quot;#博客的初心&quot; class=&quot;headerlink&quot; title=&quot;博客的初心&quot;&gt;&lt;/a&gt;博客的初心&lt;/h2&gt;&lt;p&gt;希望记录平时遇到的问题和知识或所思所想！&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;其实一直以来喜欢瞎折腾;(Ps):其实我弄水晶头</summary>
      
    
    
    
    
    <category term="生活" scheme="http://example.com/tags/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>未定义</title>
    <link href="http://example.com/2021/07/12/%E7%94%9F%E6%B4%BB/%E6%9C%AA%E5%AE%9A%E4%B9%89/"/>
    <id>http://example.com/2021/07/12/%E7%94%9F%E6%B4%BB/%E6%9C%AA%E5%AE%9A%E4%B9%89/</id>
    <published>2021-07-12T12:20:15.414Z</published>
    <updated>2021-07-12T13:21:45.223Z</updated>
    
    <content type="html"><![CDATA[<p><strong>自定义</strong></p><p>感谢你的分享的音乐，让我成长很多，也感谢认识你</p><p>虽然相见短暂，但是让我明白相见恨晚意义，如此相见不如怀恋</p><p>虽然知道你的联系方式，但是并不知道如何联系你，不想打扰你更多的是不知如何开口的尴尬</p><p>你的努力、奋斗、坚持、不抛弃、不放弃、一切皆有可能。</p><p>让我有所惭愧，我不知如何行动。我并未遗忘，只是不知如何回应。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;自定义&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;感谢你的分享的音乐，让我成长很多，也感谢认识你&lt;/p&gt;
&lt;p&gt;虽然相见短暂，但是让我明白相见恨晚意义，如此相见不如怀恋&lt;/p&gt;
&lt;p&gt;虽然知道你的联系方式，但是并不知道如何联系你，不想打扰你更多的是不知如何开口的尴尬&lt;</summary>
      
    
    
    
    
    <category term="生活" scheme="http://example.com/tags/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>Django框架之项目创建</title>
    <link href="http://example.com/2021/07/09/web%E5%BC%80%E5%8F%91%E4%B9%8BDjango%E6%A1%86%E6%9E%B6/Django%E6%A1%86%E6%9E%B6%E4%B9%8B%E9%A1%B9%E7%9B%AE%E5%88%9B%E5%BB%BA/"/>
    <id>http://example.com/2021/07/09/web%E5%BC%80%E5%8F%91%E4%B9%8BDjango%E6%A1%86%E6%9E%B6/Django%E6%A1%86%E6%9E%B6%E4%B9%8B%E9%A1%B9%E7%9B%AE%E5%88%9B%E5%BB%BA/</id>
    <published>2021-07-09T05:16:20.819Z</published>
    <updated>2021-07-09T05:17:16.151Z</updated>
    
    
    
    
    
    <category term="技术" scheme="http://example.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>Django框架之基础</title>
    <link href="http://example.com/2021/07/09/web%E5%BC%80%E5%8F%91%E4%B9%8BDjango%E6%A1%86%E6%9E%B6/Django%E6%A1%86%E6%9E%B6%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%AF%87/"/>
    <id>http://example.com/2021/07/09/web%E5%BC%80%E5%8F%91%E4%B9%8BDjango%E6%A1%86%E6%9E%B6/Django%E6%A1%86%E6%9E%B6%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%AF%87/</id>
    <published>2021-07-09T05:01:44.633Z</published>
    <updated>2021-07-09T05:29:20.495Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Django框架之基础</strong></p><ul><li><p>Django是用Python语言写的开源web开发框架，并遵循MVC设计。是劳伦斯出版集团开发新闻网站而开发的框架，于2005年7月在BSD许可证发布。</p></li><li><p>MVC框架核心思想是：解耦，让不同的代码之间降低耦合，增强代码的可扩展性和可移植性。</p></li></ul><p>MVC设计流程图：</p><p>客户端————————————&gt;服务器——————————————&gt;数据库</p><p>发出请求———————————&gt;接收请求处理返回结果————————</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;strong&gt;Django框架之基础&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Django是用Python语言写的开源web开发框架，并遵循MVC设计。是劳伦斯出版集团开发新闻网站而开发的框架，于2005年7月在BSD许可证发布。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;</summary>
      
    
    
    
    
    <category term="技术" scheme="http://example.com/tags/%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>黑夜</title>
    <link href="http://example.com/2021/07/04/%E9%BB%91%E5%A4%9C/"/>
    <id>http://example.com/2021/07/04/%E9%BB%91%E5%A4%9C/</id>
    <published>2021-07-04T15:55:21.657Z</published>
    <updated>2021-05-16T04:34:39.629Z</updated>
    
    <content type="html"><![CDATA[<h2 id="夜"><a href="#夜" class="headerlink" title="夜"></a>夜</h2><p>熙熙攘攘 白昼<br>灯火通明 夜晚<br>黑夜的宁静是多么安详<br>也让浮躁喧闹的事物变得瞬间停留<br>也许是安静让人所思所想<br>也许是内心的停留<br>让黑夜活在黑的宁静，黑夜的聆听<br>让微风拂过心中一丝思索<br>也是对黑夜的尊敬与敬畏之心<br>夜是那么黑，心是那么明<br>宁听黑夜的微凉，凉过心中的执念<br>宁听心间的黑夜与思考，黑夜才是最好的向往</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;夜&quot;&gt;&lt;a href=&quot;#夜&quot; class=&quot;headerlink&quot; title=&quot;夜&quot;&gt;&lt;/a&gt;夜&lt;/h2&gt;&lt;p&gt;熙熙攘攘 白昼&lt;br&gt;灯火通明 夜晚&lt;br&gt;黑夜的宁静是多么安详&lt;br&gt;也让浮躁喧闹的事物变得瞬间停留&lt;br&gt;也许是安静让人所思所想&lt;br&gt;也许是内</summary>
      
    
    
    
    
    <category term="生活" scheme="http://example.com/tags/%E7%94%9F%E6%B4%BB/"/>
    
  </entry>
  
</feed>
